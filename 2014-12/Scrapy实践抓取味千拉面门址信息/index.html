<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>Scrapy实践——抓取味千拉面门址信息 - pengming's blog</title>
    <meta name="description" content="jelyll theme">
    <meta name="author" content="hushaw">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="/static/favicon.ico" rel="shortcut icon">
    <link href="/static/css/bootstrap.css" rel="stylesheet" type="text/css" media="all">
    <link href="/static/css/font-awesome.css" rel="stylesheet" type="text/css" media="all">
    <link href="/static/google-code-prettify/prettify.css" rel="stylesheet" type="text/css" media="all">
    <link href="/static/css/application.css" rel="stylesheet" type="text/css" media="all">
    <script src="/static/js/jquery.js" type="text/javascript"></script>
    <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
</head>
<body>
     <div class="page-container">
     <div class="page-heading">
         <div class="page-brand">
             <h1><a href="/">心藏一片海</a></h1>
             <h2>因为深情，所以偏执；因为寡言，所以沉默；因为昏聩，所以存留</h2>
         </div>
         <div class="page-navbar">
             <div class="page-navbar-container">
                 <ul class="page-nav">
                     <li><a href="/">Home</a></li>
                     <li><a href="/archive.html">Archive</a></li>
                     <li><a href="/about.html">About</a></li>
                 </ul>
             </div>
         </div>
     </div>
     <div class="page-article">
         <div class="page-content">
    <div class="post-heading">
        Scrapy实践——抓取味千拉面门址信息
    </div>
    <div class="post-meta">
        <span>
            发布时间:
            <a href="/2014-12/Scrapy%E5%AE%9E%E8%B7%B5%E6%8A%93%E5%8F%96%E5%91%B3%E5%8D%83%E6%8B%89%E9%9D%A2%E9%97%A8%E5%9D%80%E4%BF%A1%E6%81%AF/">2014年12月07日</a>
        </span>
        <span><i class="fa fa-ellipsis-v"></i></span>
        <span>
            分类:
            
            <a href="/categories.html#数据，爬虫-ref">数据，爬虫</a>
            
        </span>
        <span><i class="fa fa-ellipsis-v"></i></span>
        <span>
            标签:
            
            <a href="/tags.html#地图，数据，位置，商业-ref">地图，数据，位置，商业</a>
            
        <span>
    </div>
    <div class="post-entry">
        <h2>一.绪言</h2>

<p>11月我写了一篇用Scrapy抓取赛百味连锁店的文章，赛百味的页面结构简单，只能当作Scrapy的入门阅读。今天要抓取的是味千拉面的连锁店门址信息，味千拉面的页面结构中等难度，应用广泛，作为Scrapy的真正实践最好不过。</p>

<h2>二.页面分析</h2>

<p>味千拉面属于经营日式拉面的的一种，我光顾过几次，价格略贵（30元一碗），味道尚可。味千的门店信息页面（<a href="http://www.ajisen.com.cn/sale-net.php">猛戳这里</a> ）。</p>

<p><img src="http://i.imgur.com/ODOmpgQ.png" alt="" /></p>

<p>这个地图页面上提供了分省的每个味千门店的入口，进入后能发现我们要抓取的数据是按照页码，每页5个排列的。不难发现，第一步要得到所以分省的链接地址；第二步，要得到每个省单独页面的页码；第三步，遍历分省链接地址与页码的组合。</p>

<h2>三.实施抓取</h2>

<p>首先，在items.py中定义要抓取的元素。</p>

<pre><code>class ajisenItem(scrapy.Item):
    shopname = scrapy.Field()
    address = scrapy.Field()
    tel = scrapy.Field()</code></pre>


<p>其次，编写爬虫
添加items引用</p>

<pre><code>from chainstore.items import ajisenItem</code></pre>


<p>完整的爬虫程序如下：</p>

<pre><code>class ajisenSpider(scrapy.Spider):
    name = "ajisen"
    start_urls = ["http://www.ajisen.com.cn/sale-net.php"]
    def parse(self, response):
        html = BeautifulSoup(response.body)
        map_link = html.find("div",class_="map_link")
        link = map_link.find_all('div')
        for lk in link:
            nextlk = lk.find('a')['href']
            #yield scrapy.Request(nextlk, callback=self.parse_page)
            yield scrapy.Request(nextlk, callback=lambda response, lk=nextlk: self.parse_page(response,lk))

    def parse_page(self, response,lk):
        html = BeautifulSoup(response.body)
        print lk
        try:
            page = html.find("font",class_= "cr_red").text
            for p in range(int(page)):
                link = lk + '&page=' + str(p)
                yield scrapy.Request(link, callback=self.parse_subpage)
        except:
            print "error"

    def parse_subpage(self,response):
        subhtml = BeautifulSoup(response.body)
        subul = subhtml.findAll("ul",class_ = "map_info_list_p")
        for ul in subul:
            subli = ul.findAll("li")
            shopname = subli[0].text
            address = subli[1].text[3:]
            tel = subli[2].text[3:]
            print shopname,address,tel
            item = ajisenItem()
            item['shopname'] = shopname
            item['address'] = address
            item['tel'] = tel
            yield item</code></pre>


<p>需要注意的是，scrapy用parse去解析入口页面，然后通过回调的方式去解析每个单独的子页面。scrapy提交一个链接请求是用 Request(url,callback=func) 这种形式的，而parse只有一个response参数，如果自定义一个有多参数的parse可以考虑用lambda匿名函数方法实现多个参数传递，将要传过来的链接参数封装到lambda中。</p>

<h2>四.输出结果</h2>

<p>采用最简单有效的保存数据方法：</p>

<pre><code>scrapy crawl ajisen -o ajisen.json</code></pre>


<p><img src="http://i.imgur.com/zyluuGO.png" alt="" /></p>

    </div>
</div>
<div class="post-blank post-pager">
    <ul class="pager">
        
        <li class="previous"><a href="/2014-12/%E6%88%91%E7%9A%84%E6%8A%97%E7%97%94%E6%97%A5%E8%AE%B0/">&larr; 上一篇</a></li>
        
        
    </ul>
</div>
<!--<div class="page-blank">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        var disqus_shortname = 'shawhu';
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>
        Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a>
    </noscript>
</div>

-->
<div class="ds-thread"></div>
<script type="text/javascript">
var duoshuoQuery = {short_name:"pengm"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0]
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>

     </div>
     <div class="page-footer">
         <span>
             Powered by <a href="https://github.com/mojombo/jekyll">Jekyll</a> 
             | Hosted by <a href="http://github.com">Github.com</a> 
             | UI Designed by <a href="/about.html">hushaw</a> 
             | <span class="page-generator-time">2014年12月09日 16时34分24秒 </span> 
             | 本站理念：心藏一片海，无所畏惧..
         </span>
     </div>
     </div>
     <script src="/static/js/bootstrap.js" type="text/javascript"></script>
     <script src="/static/google-code-prettify/prettify.js" type="text/javascript"></script>
     <script type="text/javascript">
        $(document).ready(function() {
            $('pre').addClass('prettyprint').attr('style', 'overflow:auto');
            prettyPrint();
        });
     </script>
     <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-56259167-1', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>

